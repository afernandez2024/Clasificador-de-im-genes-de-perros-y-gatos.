# -*- coding: utf-8 -*-
"""Clasificador de imágenes de perros y gatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V-mHv6LgWmQZhr8XWXcV1n5-iefeF-5c
"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip
zip_dir = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)
base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Check if the test directory exists
test_dir = os.path.join(base_dir, 'test')
if not os.path.exists(test_dir):
    # If not, create the directory
    os.makedirs(test_dir)

train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')
val_cats_dir = os.path.join(validation_dir, 'cats')
val_dogs_dir = os.path.join(validation_dir, 'dogs')

BATCH_SIZE = 128
IMG_HEIGHT = 150
IMG_WIDTH = 150

train_image_generator = ImageDataGenerator(rescale=1./255)
validation_image_generator = ImageDataGenerator(rescale=1./255)
test_image_generator = ImageDataGenerator(rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=train_dir,
    shuffle=True,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary')

val_data_gen = validation_image_generator.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=validation_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary')

test_data_gen = test_image_generator.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=test_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode=None,
    shuffle=False)

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

sample_training_images, _ = next(train_data_gen)
plotImages(sample_training_images[:5])

train_image_generator = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

train_data_gen = train_image_generator.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=train_dir,
    shuffle=True,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary')

train_image_generator = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

train_data_gen = train_image_generator.flow_from_directory(
    batch_size=BATCH_SIZE,
    directory=train_dir,
    shuffle=True,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    class_mode='binary')

augmented_images, _ = next(train_data_gen)
plotImages(augmented_images[:5])

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

# Calcular steps_per_epoch y validation_steps
steps_per_epoch = total_train // BATCH_SIZE
validation_steps = total_val // BATCH_SIZE

# Entrenar el modelo
history = model.fit(
    train_data_gen,
    steps_per_epoch=steps_per_epoch,
    epochs=EPOCHS,
    validation_data=val_data_gen,
    validation_steps=validation_steps
)

# Obtener los valores de precisión y pérdida del historial de entrenamiento
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

# Graficar precisión y pérdida
plt.figure(figsize=(16,8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Precisión de Entrenamiento')
plt.plot(epochs_range, val_acc, label='Precisión de Validación')
plt.legend(loc='lower right')
plt.title('Precisión de Entrenamiento y Validación')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Pérdida de Entrenamiento')
plt.plot(epochs_range, val_loss, label='Pérdida de Validación')
plt.legend(loc='upper right')
plt.title('Pérdida de Entrenamiento y Validación')
plt.show()

# Evaluar el modelo en el conjunto de validación
val_loss, val_accuracy = model.evaluate(val_data_gen, steps=validation_steps)
print(f"Precisión en validación: {val_accuracy * 100:.2f}%")

# Reiniciar el generador de validación
val_data_gen.reset()

# Obtener las predicciones
predictions = model.predict(val_data_gen, steps=validation_steps, verbose=1)
predicted_classes = np.where(predictions > 0.5, 1, 0)

# Obtener las etiquetas reales
true_classes = val_data_gen.classes
true_classes = true_classes[:len(predicted_classes)]

# Obtener los nombres de las clases
class_indices = val_data_gen.class_indices
class_labels = list(class_indices.keys())
label_map = dict((v,k) for k,v in class_indices.items())

# Función para visualizar imágenes con sus predicciones
def plotImages(images_arr, labels, predictions):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, lbl, pred, ax in zip(images_arr, labels, predictions, axes):
        ax.imshow(img)
        ax.set_title(f"Real: {label_map[int(lbl)]}\nPred: {label_map[int(pred)]}")
        ax.axis('off')
    plt.tight_layout()
    plt.show()

# Obtener imágenes y etiquetas del generador
val_data_gen.reset()
images, labels = next(val_data_gen)

# Mostrar las primeras 5 imágenes con sus predicciones
plotImages(images[:5], labels[:5], predicted_classes[:5])